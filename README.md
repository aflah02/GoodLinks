# GoodLinks

## Pytorch
- [Weight Tying LSTM Encoder Decoder](https://discuss.pytorch.org/t/best-way-to-tie-lstm-weights/12504/8)

## HuggingFace
- [Model Internal Layer Outputs Explanation](https://medium.com/@dhartidhami/understanding-bert-word-embeddings-7dc4d2ea54ca#:~:text=hidden_states%20has%20four%20dimensions%2C%20in,22%20tokens%20in%20our%20sentence)
- [Hidden States](https://github.com/huggingface/transformers/issues/1827)
